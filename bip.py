import requests
from bs4 import BeautifulSoup
import time
import re

# StaÅ‚e dla skryptu
BASE_URL = "https://ssdip.bip.gov.pl/search/graphsubjects/"
URL_SUFFIX = "state_id:25/substate_id:557" 
BIP_LIST_FILENAME = 'bip_list.txt'

bip_urls = set()
page_num = 1
max_pages_check = 20 # Zmienna ograniczajÄ…ca pÄ™tlÄ™ na wypadek bÅ‚Ä™du w identyfikacji koÅ„ca

print("ğŸ” Rozpoczynanie pobierania listy portali BIP...")

# Ustalenie, ile stron ma lista (z Twojego HTML wynika, Å¼e jest ich 17)
# Zmieniamy pÄ™tlÄ™ na while, ktÃ³ra bÄ™dzie szukaÄ‡ linku do ostatniej strony
last_page_element = None 
try:
    response = requests.get(f"{BASE_URL}{URL_SUFFIX}", timeout=10)
    soup = BeautifulSoup(response.text, 'html.parser')
    # Znajdujemy link 'last' i wyodrÄ™bniamy numer strony z atrybutu href
    last_page_link = soup.select_one('div.paging a.last')
    if last_page_link:
        # PrzykÅ‚adowy href: /search/graphsubjects/page:17/state_id:25/substate_id:557
        match = re.search(r'page:(\d+)', last_page_link.get('href', ''))
        if match:
            max_pages_check = int(match.group(1))
            print(f"Znaleziono caÅ‚kowitÄ… liczbÄ™ stron: {max_pages_check}.")
except Exception as e:
    print(f"BÅ‚Ä…d przy prÃ³bie ustalenia max. stron: {e}. UÅ¼ywam domyÅ›lnego limitu {max_pages_check}.")

# PÄ™tla iterujÄ…ca po stronach
while page_num <= max_pages_check:
    # UÅ¼ywamy formatu URL z paginacjÄ…, ktÃ³ry Pan podaÅ‚
    url = f"{BASE_URL}page:{page_num}/{URL_SUFFIX}"
    if page_num == 1:
        url = f"{BASE_URL}{URL_SUFFIX}" # Strona 1 nie musi mieÄ‡ page:1

    print(f"\n---> Przetwarzanie strony: {page_num} ({url})")

    try:
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'html.parser')

        # CELUJEMY W WIERSZE Z DANYMI BIP-Ã“W
        rows = soup.select('table.wyniki_szukania tr.color')
        
        new_links_count_on_page = 0
        
        if not rows:
            print("   [INFO] Brak wierszy z danymi. Koniec listy lub bÅ‚Ä…d parsowania.")
            break
            
        for row in rows:
            # Kolumny (td):
            # 0: numer
            # 1: Nazwa + Adres (tekst)
            # 2: Strona (link URL) <-- TEN CHCEMY
            # 3: WiÄ™cej
            
            columns = row.find_all('td')
            
            # Musimy mieÄ‡ przynajmniej 3 kolumny, aby znaleÅºÄ‡ adres
            if len(columns) > 2:
                # 3. WyodrÄ™bnienie linku z trzeciej kolumny (indeks 2)
                link_element = columns[2].find('a')
                
                if link_element:
                    href = link_element.get('href')
                    
                    # Weryfikacja i normalizacja URL (upewnienie siÄ™, Å¼e link ma protokÃ³Å‚ i jest BIP-em)
                    if href and 'bip.gov.pl' in href and href.startswith('http'):
                         # W podanym HTML link jest juÅ¼ URL-em bazowym (np. http://agencjabadmed.bip.gov.pl)
                        base_url = href.strip()
                        
                        if base_url not in bip_urls:
                            bip_urls.add(base_url)
                            new_links_count_on_page += 1

        if new_links_count_on_page > 0:
            print(f"âœ… Znaleziono {new_links_count_on_page} nowych adresÃ³w. ÅÄ…cznie: {len(bip_urls)}.")
        else:
            print(f"âš ï¸ Nie znaleziono nowych adresÃ³w na tej stronie.")

    except requests.exceptions.RequestException as e:
        print(f"ğŸ›‘ BÅ‚Ä…d podczas pobierania strony {page_num}: {e}")
        break
    except Exception as e:
        print(f"ğŸ›‘ WystÄ…piÅ‚ nieoczekiwany bÅ‚Ä…d parsowania na stronie {page_num}: {e}")
        break

    page_num += 1
    time.sleep(0.5) # KrÃ³tki odstÄ™p

# Zapisanie wynikÃ³w do pliku
with open(BIP_LIST_FILENAME, 'w', encoding='utf-8') as f:
    for url in sorted(list(bip_urls)):
        f.write(url + '\n')

print(f"\n--- ZakoÅ„czono FazÄ™ 1 ---")
print(f"âœ… Zapisano {len(bip_urls)} unikatowych adresÃ³w BIP do pliku **{BIP_LIST_FILENAME}**")